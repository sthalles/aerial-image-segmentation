{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import tensorflow as tf\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET_DIR=\"../dataset/\"\n",
    "TRAIN_FILE = 'train.tfrecords'\n",
    "VALIDATION_FILE = 'validation.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"image_raw\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "        'annotation_raw': tf.FixedLenFeature([], tf.string),\n",
    "        \"height\": tf.FixedLenFeature((), tf.int64),\n",
    "        \"width\": tf.FixedLenFeature((), tf.int64)\n",
    "    }\n",
    "    \n",
    "    features = tf.parse_single_example(record, keys_to_features)\n",
    "    \n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    annotation = tf.decode_raw(features['annotation_raw'], tf.uint8)\n",
    "\n",
    "    height = tf.cast(features['height'], tf.int32)\n",
    "    width = tf.cast(features['width'], tf.int32)\n",
    "    \n",
    "    image = tf.reshape(image, (height,width,3), name=\"image_reshape\")\n",
    "    annotation = tf.reshape(annotation, (height,width), name=\"annotation_reshape\")\n",
    "    \n",
    "    return image, annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_flip_image_and_annotation(image_tensor, annotation_tensor):\n",
    "    \"\"\"Accepts image tensor and annotation tensor and returns randomly flipped tensors of both.\n",
    "    The function performs random flip of image and annotation tensors with probability of 1/2\n",
    "    The flip is performed or not performed for image and annotation consistently, so that\n",
    "    annotation matches the image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_tensor : Tensor of size (width, height, 3)\n",
    "        Tensor with image\n",
    "    annotation_tensor : Tensor of size (width, height, 1)\n",
    "        Tensor with annotation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    randomly_flipped_img : Tensor of size (width, height, 3) of type tf.float.\n",
    "        Randomly flipped image tensor\n",
    "    randomly_flipped_annotation : Tensor of size (width, height, 1)\n",
    "        Randomly flipped annotation tensor\n",
    "\n",
    "    \"\"\"\n",
    "    annotation_tensor = tf.expand_dims(annotation_tensor, axis=2)\n",
    "\n",
    "    # Random variable: two possible outcomes (0 or 1)\n",
    "    # with a 1 in 2 chance\n",
    "    random_var = tf.random_uniform(maxval=2, dtype=tf.int32, shape=[])\n",
    "\n",
    "\n",
    "    randomly_flipped_img = tf.cond(pred=tf.equal(random_var, 0),\n",
    "                                                 true_fn=lambda: tf.image.flip_left_right(image_tensor),\n",
    "                                                 false_fn=lambda: image_tensor)\n",
    "\n",
    "    randomly_flipped_annotation = tf.cond(pred=tf.equal(random_var, 0),\n",
    "                                                        true_fn=lambda: tf.image.flip_left_right(annotation_tensor),\n",
    "                                                        false_fn=lambda: annotation_tensor)\n",
    "\n",
    "    return randomly_flipped_img, tf.squeeze(randomly_flipped_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cutout(image, label):\n",
    "    cutout_shape = [24,24]\n",
    "    \n",
    "    def random_cutout(image):\n",
    "        center_x = np.random.randint(0, image.shape[0])\n",
    "        center_y = np.random.randint(0, image.shape[0])\n",
    "\n",
    "        # check boundaries conditions\n",
    "        from_x = center_x-cutout_shape[0]//2 if center_x-cutout_shape[0]//2 > 0 else 0\n",
    "        to_x = image.shape[0] if (center_x+cutout_shape[0]//2) > image.shape[0] else center_x+cutout_shape[0]//2\n",
    "\n",
    "        from_y = center_y-cutout_shape[0]//2 if center_y-cutout_shape[0]//2 > 0 else 0\n",
    "        to_y = image.shape[1] if (center_y+cutout_shape[0]//2) > image.shape[1] else center_y+cutout_shape[1]//2\n",
    "\n",
    "        image[from_x:to_x,from_y:to_y] = 0\n",
    "        return image\n",
    "    \n",
    "    return tf.py_func(random_cutout, [image], (image.dtype)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filenames = [os.path.join(TRAIN_DATASET_DIR,TRAIN_FILE)]\n",
    "training_dataset = tf.contrib.data.TFRecordDataset(training_filenames)\n",
    "training_dataset = training_dataset.map(parser)  # Parse the record into tensors.\n",
    "training_dataset = training_dataset.map(random_flip_image_and_annotation)  \n",
    "\n",
    "training_dataset = training_dataset.map(cutout)\n",
    "\n",
    "#training_dataset = training_dataset.map(\n",
    "#    lambda image, label: tf.py_func(\n",
    "#        cutout, [(image)], (image.dtype)), label)\n",
    "\n",
    "training_dataset = training_dataset.repeat()  # number of epochs\n",
    "training_dataset = training_dataset.batch(64)\n",
    "training_dataset = training_dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "validation_filenames = [os.path.join(TRAIN_DATASET_DIR,VALIDATION_FILE)]\n",
    "validation_dataset = tf.contrib.data.TFRecordDataset(validation_filenames)\n",
    "validation_dataset = validation_dataset.map(parser)  # Parse the record into tensors.\n",
    "validation_dataset = validation_dataset.batch(1)\n",
    "\n",
    "# A feedable iterator is defined by a handle placeholder and its structure. We\n",
    "# could use the `output_types` and `output_shapes` properties of either\n",
    "# `training_dataset` or `validation_dataset` here, because they have\n",
    "# identical structure.\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.contrib.data.Iterator.from_string_handle(\n",
    "    handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# You can use feedable iterators with a variety of different kinds of iterator\n",
    "# (such as one-shot and initializable iterators).\n",
    "training_iterator = training_dataset.make_initializable_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(training_iterator.initializer)\n",
    "    # The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "    # and used to feed the `handle` placeholder.\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    #sess.run(training_iterator.initializer)\n",
    "    \n",
    "    while True:\n",
    "        for i in range(8):\n",
    "            image_batch, annotation_batch = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "            f, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2, 4, sharey=True, figsize=(15,7))\n",
    "            idx = random.sample(range(32), 8)\n",
    "            ax1.imshow(image_batch[idx[0]])\n",
    "            ax2.imshow(image_batch[idx[1]])\n",
    "            ax3.imshow(image_batch[idx[2]])\n",
    "            ax4.imshow(image_batch[idx[3]])\n",
    "            ax5.imshow(annotation_batch[idx[0]])\n",
    "            ax6.imshow(annotation_batch[idx[1]])\n",
    "            ax7.imshow(annotation_batch[idx[2]])\n",
    "            ax8.imshow(annotation_batch[idx[3]])\n",
    "            plt.show()\n",
    "            counter+=1\n",
    "        \n",
    "        print(\"End of epoch:\", i)\n",
    "\n",
    "        # Initialize `iterator` with validation data.\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for i in range(4):\n",
    "            try:\n",
    "                image_batch, annotation_batch = sess.run(next_element, feed_dict={handle: validation_handle})\n",
    "                print(annotation_batch.shape)\n",
    "                f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(14,7))\n",
    "                ax1.imshow(image_batch[0])\n",
    "                ax2.imshow(annotation_batch[0])\n",
    "                plt.show()\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"End of validation\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6f323519b173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraining_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATASET_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRAIN_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtraining_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Parse the record into tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#training_dataset = training_dataset.map(random_flip_image_and_annotation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCudnnGRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCudnnLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCudnnRNNRelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_cudnn_rnn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlstm_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcommon_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/rnn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatic_bidirectional_rnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/rnn_cell.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mop_def_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# pylint: disable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;31m# pylint: enable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontrib_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbucketization_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_feature_cross_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0moutputs_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m     \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m     scope=None):\n\u001b[0m\u001b[1;32m   1065\u001b[0m   \"\"\"Performs the same in-plane convolution to each channel independently.\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36madd_arg_scope\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_key_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_with_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \"\"\"\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdecorator_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mdecorator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Caller's name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m   decorator = TFDecorator(decorator_name, target, decorator_doc,\n\u001b[1;32m     88\u001b[0m                           decorator_argspec)\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    736\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;31m# or it is in the linecache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;31m# Copy sys.modules in order to cope with changes while iterating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_filesbymodname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mismodule\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# ----------------------------------------------------------- type-checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \"\"\"Return true if the object is a module.\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the total number of images in the tf record training set\n",
    "number_of_images = 0\n",
    "for fn in training_filenames:\n",
    "    for record in tf.python_io.tf_record_iterator(fn):\n",
    "        number_of_images += 1\n",
    "\n",
    "training_filenames = [os.path.join(TRAIN_DATASET_DIR,TRAIN_FILE)]\n",
    "training_dataset = tf.contrib.data.TFRecordDataset(training_filenames)\n",
    "training_dataset = training_dataset.map(parser)  # Parse the record into tensors.\n",
    "#training_dataset = training_dataset.map(random_flip_image_and_annotation)  \n",
    "#training_dataset = training_dataset.map(cutout)\n",
    "\n",
    "training_dataset = training_dataset.repeat(1)  # number of epochs\n",
    "training_dataset = training_dataset.batch(1)\n",
    "#training_dataset = training_dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "validation_filenames = [os.path.join(TRAIN_DATASET_DIR,VALIDATION_FILE)]\n",
    "validation_dataset = tf.contrib.data.TFRecordDataset(validation_filenames)\n",
    "validation_dataset = validation_dataset.map(parser)  # Parse the record into tensors.\n",
    "validation_dataset = validation_dataset.batch(1)\n",
    "\n",
    "# A feedable iterator is defined by a handle placeholder and its structure. We\n",
    "# could use the `output_types` and `output_shapes` properties of either\n",
    "# `training_dataset` or `validation_dataset` here, because they have\n",
    "# identical structure.\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.contrib.data.Iterator.from_string_handle(\n",
    "    handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# You can use feedable iterators with a variety of different kinds of iterator\n",
    "# (such as one-shot and initializable iterators).\n",
    "training_iterator = training_dataset.make_initializable_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "r_mean, g_mean, b_mean = 0.,0.,0.\n",
    "\n",
    "total_number_of_pixels_class_0 = 0.\n",
    "total_number_of_pixels_class_1 = 0.\n",
    "total_number_of_pixels_class_2 = 0.\n",
    "\n",
    "r_std, g_std, b_std = 0.,0.,0.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(training_iterator.initializer)\n",
    "    # The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "    # and used to feed the `handle` placeholder.\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    #sess.run(training_iterator.initializer)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            image_batch, annotation_batch = sess.run(next_element, feed_dict={handle: training_handle})\n",
    "            image = np.squeeze(image_batch)\n",
    "            annotation = np.squeeze(annotation_batch)\n",
    "            \n",
    "            if counter == 0:\n",
    "                image_height = image.shape[0]\n",
    "                image_width = image.shape[1]\n",
    "                \n",
    "            # get the mean values for each of the channels\n",
    "            r_mean += np.mean(image[:,:,0]) # R\n",
    "            g_mean += np.mean(image[:,:,1]) # G\n",
    "            b_mean += np.mean(image[:,:,2]) # B\n",
    "\n",
    "            r_std += np.std(image[:,:,0])\n",
    "            g_std += np.std(image[:,:,1])\n",
    "            b_std += np.std(image[:,:,2])\n",
    "\n",
    "            cnt_class_0 = 0\n",
    "            cnt_class_1 = 0\n",
    "            cnt_class_2 = 0\n",
    "\n",
    "            for i in range(64):\n",
    "                for j in range(64):\n",
    "                    if (annotation[i,j] == 0):\n",
    "                        cnt_class_0 += 1\n",
    "                    elif (annotation[i,j] == 1):\n",
    "                        cnt_class_1 += 1\n",
    "                    elif (annotation[i,j] == 2):\n",
    "                        cnt_class_2 += 1\n",
    "\n",
    "            total_number_of_pixels_class_0 += cnt_class_0\n",
    "            total_number_of_pixels_class_1 += cnt_class_1\n",
    "            total_number_of_pixels_class_2 += cnt_class_2\n",
    "            \n",
    "            counter+=1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of dataset\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = sum(1 for _ in tf.python_io.tf_record_iterator(training_filenames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 561152\n"
     ]
    }
   ],
   "source": [
    "print(\"Size:\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Mean: 84.7362072189\n",
      "G Mean: 86.0941014747\n",
      "B Mean: 78.4789828349\n",
      "R Std: 43.0708766207\n",
      "G Std: 41.7703955642\n",
      "B Std: 42.0244728104\n"
     ]
    }
   ],
   "source": [
    "print(\"R Mean:\", r_mean/size)\n",
    "print(\"G Mean:\", g_mean/size)\n",
    "print(\"B Mean:\", b_mean/size)\n",
    "\n",
    "print(\"R Std:\", r_std/size)\n",
    "print(\"G Std:\", g_std/size)\n",
    "print(\"B Std:\", b_std/size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1672943358.0, 363715747.0, 261819487.0]\n",
      "[  2.61819487e+08   3.63715747e+08   1.67294336e+09]\n"
     ]
    }
   ],
   "source": [
    "total_number_of_pixels_per_class = [total_number_of_pixels_class_0, total_number_of_pixels_class_1, total_number_of_pixels_class_2]\n",
    "print(total_number_of_pixels_per_class)\n",
    "print(np.sort(total_number_of_pixels_per_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  0.,  1.]),\n",
       " array([  2.61819487e+08,   7.32194111e+08,   1.20256873e+09,\n",
       "          1.67294336e+09]),\n",
       " <a list of 3 Patch objects>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEJCAYAAACT/UyFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64886dc278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(total_number_of_pixels_per_class, bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1672943358.0, 363715747.0, 261819487.0]\n"
     ]
    }
   ],
   "source": [
    "print(total_number_of_pixels_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.599590124427579\n",
      "6.389682361573033\n",
      "1.389185164051597\n"
     ]
    }
   ],
   "source": [
    "print(total_number_of_pixels_class_0/total_number_of_pixels_class_1)\n",
    "print(total_number_of_pixels_class_0/total_number_of_pixels_class_2)\n",
    "print(total_number_of_pixels_class_1/total_number_of_pixels_class_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234000000\n"
     ]
    }
   ],
   "source": [
    "total_number_of_pixels_where_class_c_is_present = number_of_images * image_height * image_width # number of images * image_weight * image_width\n",
    "print(total_number_of_pixels_where_class_c_is_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.14933058974359, 1.554340799145299, 1.1188866965811965]\n"
     ]
    }
   ],
   "source": [
    "# weight for class 0 (Background)\n",
    "\n",
    "# where freq(c) is the number of pixels of class c divided by the total number of pixels in images where c is present\n",
    "freq_class_0 = total_number_of_pixels_class_0 / total_number_of_pixels_where_class_c_is_present\n",
    "freq_class_1 = total_number_of_pixels_class_1 / total_number_of_pixels_where_class_c_is_present\n",
    "freq_class_2 = total_number_of_pixels_class_2 / total_number_of_pixels_where_class_c_is_present\n",
    "class_frequencies = [freq_class_0,freq_class_1,freq_class_2]\n",
    "print(class_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.55434079915\n"
     ]
    }
   ],
   "source": [
    "# and median_freq is the median of all class frequencies. \n",
    "median_freq = np.median(class_frequencies)\n",
    "print(median_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight class 0: 0.217410676375\n",
      "Weight class 1: 1.0\n",
      "Weight class 2: 1.38918516405\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight class 0:\", median_freq/freq_class_0)\n",
    "print(\"Weight class 1:\", median_freq/freq_class_1)\n",
    "print(\"Weight class 2:\", median_freq/freq_class_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "image = tf.Variable(tf.ones((64,64)))\n",
    "sess = tf.Session()\n",
    "cutout_shape = [24,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(image.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center_x = tf.cast(tf.random_uniform([1], maxval=tf.to_float(tf.shape(image)[0]))[0], dtype=tf.int32)\n",
    "center_y = tf.cast(tf.random_uniform([1], maxval=tf.to_float(tf.shape(image)[1]))[0], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 55]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([center_x, center_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from_x = tf.cond(center_x - cutout_shape[0]//2 > 0, lambda:center_x-cutout_shape[0]//2, lambda:0)\n",
    "to_x = tf.cond(center_x + cutout_shape[0]//2 > image.shape[0], lambda:image.shape[0], lambda:center_x+cutout_shape[0]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([to_x, from_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from_y = tf.cond(center_y - cutout_shape[0]//2 > 0, lambda:center_y-cutout_shape[0]//2, lambda:0)\n",
    "to_y = tf.cond(center_y + cutout_shape[0]//2 > image.shape[1], lambda:image.shape[1], lambda:center_y+cutout_shape[1]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54, 30]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([to_y, from_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutout = tf.zeros((to_x-from_x, to_y-from_y))\n",
    "g = image[from_x:to_x,from_y:to_y].assign(cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = sess.run(g)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41d007d940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_cutout(input_image):\n",
    "    cutout_shape = tf.constant([24,24])\n",
    "    \n",
    "    image = tf.get_variable(\"image_shape\", shape=(64,64,3), initializer=tf.ones_initializer())\n",
    "    sess.run(image.initializer)\n",
    "    center_x = tf.cast(tf.random_uniform([1], maxval=tf.to_float(tf.shape(image)[0]))[0], dtype=tf.int32)\n",
    "    center_y = tf.cast(tf.random_uniform([1], maxval=tf.to_float(tf.shape(image)[1]))[0], dtype=tf.int32)\n",
    "\n",
    "    from_x = tf.cond(center_x - cutout_shape[0]//2 > 0, lambda:center_x-cutout_shape[0]//2, lambda:0)\n",
    "    to_x = tf.cond(center_x + cutout_shape[0]//2 > tf.shape(image)[0], lambda:tf.shape(image)[0], lambda:center_x+cutout_shape[0]//2)\n",
    "\n",
    "    from_y = tf.cond(center_y - cutout_shape[0]//2 > 0, lambda:center_y-cutout_shape[0]//2, lambda:0)\n",
    "    to_y = tf.cond(center_y + cutout_shape[0]//2 > tf.shape(image)[1], lambda:tf.shape(image)[1], lambda:center_y+cutout_shape[1]//2)\n",
    "\n",
    "    cutout_mask = tf.zeros((to_x-from_x, to_y-from_y,3), dtype=tf.float32)\n",
    "    res = image[from_x:to_x,from_y:to_y].assign(cutout_mask)\n",
    "\n",
    "    return tf.multiply(input_image, res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
