{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imread\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import precision_recall_fscore_support, jaccard_similarity_score, confusion_matrix\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the images and annotations path\n",
    "base_dataset_dir = \"/data/Road_and_Buildings_detection_dataset/mass_merged\"\n",
    "train_dataset_base_dir = os.path.join(base_dataset_dir, \"test\")\n",
    "images_folder_name = \"sat/\"\n",
    "annotations_folder_name = \"map/\"\n",
    "train_images_dir = os.path.join(train_dataset_base_dir, images_folder_name)\n",
    "train_annotations_dir = os.path.join(train_dataset_base_dir, annotations_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_train_examples: 10\n",
      "22828930_15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the train.txt file. This file contains the training images' names\n",
    "file = open(os.path.join(train_dataset_base_dir, \"test.txt\"), 'r')\n",
    "images_filename_list = [line for line in file]\n",
    "number_of_train_examples = len(images_filename_list)\n",
    "print(\"number_of_train_examples:\", number_of_train_examples)\n",
    "print(images_filename_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saito_predictions = glob.glob(\"/data/SemanticSegmentation/Projects/ssai-cnn/results/test_results_saito_pre_trained/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22828930_15\\n', '22828990_15\\n', '22829050_15\\n', '23429020_15\\n', '23429080_15\\n', '23578960_15\\n', '23579005_15\\n', '23729035_15\\n', '23879080_15\\n', '24179065_15\\n']\n",
      "\n",
      "\n",
      "['/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/22828930_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/22828990_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/22829050_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/23429020_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/23429080_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/23578960_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/23579005_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/23729035_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/23879080_15_prediction_np.npy', '/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/24179065_15_prediction_np.npy']\n"
     ]
    }
   ],
   "source": [
    "# best sofar: 19321, 7228, \n",
    "\n",
    "our_predictions = glob.glob(\"/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209/test/*.npy\")\n",
    "print(sorted(images_filename_list))\n",
    "print(\"\\n\")\n",
    "print(sorted(our_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image_name=our_predictions[7]\n",
    "# print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ground_truth = imread(train_annotations_dir + \"/\" + \"23729035_15\" + \".tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(ground_truth)\n",
    "# print(\"ground_truth shape\", ground_truth.shape)\n",
    "# print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction_img = imread(\"/home/thalles_silva/log_folder/7228/test/\" + image_name + \"_pred_label.tiff\")\n",
    "#plt.imshow(prediction_img)\n",
    "# prediction = np.load(image_name)\n",
    "# prediction = np.squeeze(prediction)\n",
    "# print(\"prediction shape:\", prediction.shape)\n",
    "# print(prediction)\n",
    "# plt.imshow(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# int relax_precision(const np::ndarray& predict,\n",
    "#                     const np::ndarray& label, const int& relax) {\n",
    "#   const int h_lim             = predict.shape(1);\n",
    "#   const int w_lim             = predict.shape(0);\n",
    "#   const int32_t *predict_data =\n",
    "#     reinterpret_cast<int32_t *>(predict.get_data());\n",
    "#   const int32_t *label_data =\n",
    "#     reinterpret_cast<int32_t *>(label.get_data());\n",
    "\n",
    "#   int true_positive = 0;\n",
    "\n",
    "#   for (int y = 0; y < h_lim; ++y) {\n",
    "#     for (int x = 0; x < w_lim; ++x) {\n",
    "#       const int32_t pred_val = predict_data[y * w_lim + x];\n",
    "\n",
    "#       if (pred_val == 1) {\n",
    "#         const int st_y = y - relax >= 0 ? y - relax : 0;\n",
    "#         const int en_y = y + relax < h_lim ? y + relax : h_lim - 1;\n",
    "#         const int st_x = x - relax >= 0 ? x - relax : 0;\n",
    "#         const int en_x = x + relax < w_lim ? x + relax : w_lim - 1;\n",
    "#         int sum        = 0;\n",
    "\n",
    "#         for (int yy = st_y; yy <= en_y; ++yy) {\n",
    "#           for (int xx = st_x; xx <= en_x; ++xx) {\n",
    "#             sum += label_data[yy * w_lim + xx];\n",
    "#           }\n",
    "#         }\n",
    "\n",
    "#         if (sum > 0) true_positive++;\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "\n",
    "#   return true_positive;\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relax_precision(predict, label, relax):\n",
    "    h_lim = predict.shape[0]\n",
    "    w_lim = predict.shape[1]\n",
    "    true_positive = 0\n",
    "    for y in range(h_lim):\n",
    "        for x in range(w_lim):\n",
    "            pred_val = predict[y,x]\n",
    "            \n",
    "            if (pred_val == 1):\n",
    "                st_y = y if y - relax >= 0 else 0\n",
    "                en_y = y + relax if y + relax < h_lim else h_lim - 1\n",
    "                st_x = x - relax if x - relax >= 0 else 0\n",
    "                en_x = x + relax if x + relax < w_lim else w_lim - 1\n",
    "                \n",
    "                sum = 0\n",
    "                for yy in range(st_y, en_y+1):\n",
    "                    for xx in range(st_x, en_x+1):\n",
    "                        sum += label[yy,xx]\n",
    "                        \n",
    "                if (sum > 0): \n",
    "                    true_positive+=1\n",
    "    return true_positive;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# int relax_recall(const np::ndarray predict,\n",
    "#                  const np::ndarray label, const int& relax) {\n",
    "#   const int h_lim             = label.shape(1);\n",
    "#   const int w_lim             = label.shape(0);\n",
    "#   const int32_t *predict_data =\n",
    "#     reinterpret_cast<int32_t *>(predict.get_data());\n",
    "#   const int32_t *label_data =\n",
    "#     reinterpret_cast<int32_t *>(label.get_data());\n",
    "\n",
    "#   int true_positive = 0;\n",
    "\n",
    "#   for (int y = 0; y < h_lim; ++y) {\n",
    "#     for (int x = 0; x < w_lim; ++x) {\n",
    "#       const int32_t label_val = label_data[y * w_lim + x];\n",
    "\n",
    "#       if (label_val == 1) {\n",
    "#         const int st_y = y - relax >= 0 ? y - relax : 0;\n",
    "#         const int en_y = y + relax < h_lim ? y + relax : h_lim - 1;\n",
    "#         const int st_x = x - relax >= 0 ? x - relax : 0;\n",
    "#         const int en_x = x + relax < w_lim ? x + relax : w_lim - 1;\n",
    "#         int sum        = 0;\n",
    "\n",
    "#         for (int yy = st_y; yy <= en_y; ++yy) {\n",
    "#           for (int xx = st_x; xx <= en_x; ++xx) {\n",
    "#             sum += predict_data[yy * w_lim + xx];\n",
    "#           }\n",
    "#         }\n",
    "\n",
    "#         if (sum > 0) true_positive++;\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "\n",
    "#   return true_positive;\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relax_recall(predict, label, relax):\n",
    "    if predict.shape != label.shape:\n",
    "        raise(\"Error, prediction and label must be the same shape\")\n",
    "    \n",
    "    h_lim = label.shape[0]\n",
    "    w_lim = label.shape[1]\n",
    "    true_positive = 0\n",
    "    \n",
    "    for y in range(h_lim):\n",
    "        for x in range(w_lim):\n",
    "            label_val = label[y, x]\n",
    "            #print(\"(y,x)\", x,y)\n",
    "            if (label_val == 1):\n",
    "                st_y = y - relax if y - relax >= 0 else 0;\n",
    "                en_y = y + relax if y + relax < h_lim else h_lim - 1\n",
    "                st_x = x - relax if x - relax >= 0 else 0\n",
    "                en_x = x + relax if x + relax < w_lim else w_lim - 1;\n",
    "                sum = 0\n",
    "                #print(st_y,en_y,st_x,en_x)\n",
    "                for yy in range(st_y,en_y+1):\n",
    "                    for xx in range(st_x,en_x+1):\n",
    "                        #print(yy * w_lim + xx)\n",
    "                        sum += predict[yy, xx]\n",
    "                #print(\"----\")\n",
    "                if (sum > 0):\n",
    "                    true_positive+=1\n",
    "    return true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_prec_recall(pred, label, relax):\n",
    "    if pred.shape != label.shape:\n",
    "        raise(\"Error, prediction and label must be the same shape\")\n",
    "    positive = np.sum(pred == 1)\n",
    "    true = np.sum(label == 1)\n",
    "    prec_tp = relax_precision(pred, label, relax)\n",
    "    recall_tp = relax_recall(pred, label, relax)\n",
    "    \n",
    "    if prec_tp > positive or recall_tp > true:\n",
    "        print(positive, prec_tp, true, recall_tp)\n",
    "        sys.exit('Calculation is wrong.')\n",
    "\n",
    "    prec = prec_tp / float(positive) if positive > 0 else 1.0\n",
    "    recall = recall_tp / float(true) if true > 0 else 1.0\n",
    "\n",
    "    return (prec, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model_id: 11270: EldNet-8\n",
    "# Model_id: 19325: EldNet-4\n",
    "# Model id: 12887: Deeplab-8 \n",
    "# Model id: 26459: Deeplab-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = np.array([[0,1], [0,0]])\n",
    "y_pred = np.array([[1,1], [1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0]\n",
      "[1 1 1 0]\n",
      "tn: 1 fp: 2 fn: 0 tp: 1\n",
      "--->  0.333333333333\n",
      "frequency_weighted_IU 0.333333333333\n",
      "mean_IU 0.333333333333\n",
      "pixel_accuracy: 0.5\n",
      "mean_accuracy 0.666666666667\n",
      "jacard_index 0.5\n"
     ]
    }
   ],
   "source": [
    "print(y_true.flatten())\n",
    "print(y_pred.flatten())\n",
    "tn, fp, fn, tp = confusion_matrix(y_true.flatten(), y_pred.flatten()).ravel()\n",
    "print(\"tn:\", tn, \"fp:\", fp, \"fn:\", fn, \"tp:\", tp)\n",
    "\n",
    "print(\"---> \", (tp / (tp + fp + fn)))\n",
    "\n",
    "jacard_index = jaccard_similarity_score(y_true.flatten(), y_pred.flatten(), normalize=True)\n",
    "mean_IU = metrics.mean_IU(y_pred, y_true)\n",
    "pixel_accuracy = metrics.pixel_accuracy(y_pred, y_true)\n",
    "mean_accuracy = metrics.mean_accuracy(y_pred, y_true)\n",
    "frequency_weighted_IU = metrics.frequency_weighted_IU(y_pred, y_true)\n",
    "\n",
    "\n",
    "print(\"frequency_weighted_IU\",frequency_weighted_IU)\n",
    "print(\"mean_IU\",mean_IU)\n",
    "print(\"pixel_accuracy:\",pixel_accuracy)\n",
    "print(\"mean_accuracy\",mean_accuracy)\n",
    "print(\"jacard_index\", jacard_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y_true_tf = tf.constant([[0,1], [0,0]])\n",
    "y_pred_tf = tf.constant([[1,1], [1,0]])\n",
    "mean_ui, update_op = tf.metrics.mean_iou(y_true_tf, y_pred_tf, 2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    update_op.eval()\n",
    "    print(mean_ui.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for class: 1\n",
      "Mean prec: 0.95760614423 Mean recall: 0.939589730853 Mean f1: 0.94844680884 Jaccard Index 0.643702976743\n",
      "Mean IoU: 0.781901556874 Mean freq IoU: 0.870058219769 Mean acc: 0.860078877442 Mean pixel acc: 0.927870798381\n",
      "---------------\n",
      "Statistics for class: 2\n",
      "Mean prec: 0.898576473528 Mean recall: 0.86185994653 Mean f1: 0.879539077683 Jaccard Index 0.549832050963\n",
      "Mean IoU: 0.743775267147 Mean freq IoU: 0.892331439311 Mean acc: 0.828561984533 Mean pixel acc: 0.938635646193\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "relax_factor = 3\n",
    "model_id = 19209\n",
    "for class_id in [1,2]:\n",
    "    print(\"Statistics for class:\", class_id)\n",
    "    \n",
    "    mean_precision = []\n",
    "    mean_recall = []\n",
    "    mean_f1 = []\n",
    "    jaccard_average_similarity = []\n",
    "    mean_IoU_list = []\n",
    "    freq_IoU_list = []\n",
    "    mean_acc_list = []\n",
    "    pixel_acc_list = []\n",
    "    \n",
    "    # loop though all predicted images and ground thruths\n",
    "    for image_name in images_filename_list:\n",
    "\n",
    "        #prediction = np.load(\"/home/thalles_silva/log_folder/\" + str(model_id) + \"/test/\" + image_name.strip() + \"_prediction_np.npy\")\n",
    "        #/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/19209\n",
    "        prediction = np.load(\"/data/SemanticSegmentation/AerialSemanticSegmentation/tboard_logs/\" + str(model_id) + \"/test/\" + image_name.strip() + \"_prediction_np.npy\")\n",
    "        #prediction = np.load(\"/home/thalles_silva/DataPublic/SemanticSegmentation/Projects/ssai-cnn/results/test_results_saito_pre_trained/\" + image_name.strip() + \"_pred_argmax.npy\")\n",
    "        prediction = np.squeeze(prediction)\n",
    "        #print(prediction.shape)\n",
    "        \n",
    "        prediction_binary = np.zeros(prediction.shape, dtype=np.uint8)\n",
    "        label_binary = np.zeros(prediction.shape, dtype=np.uint8)\n",
    "        \n",
    "        ground_truth = imread(train_annotations_dir + \"/\" + image_name.strip() + \".tif\")\n",
    "        ground_truth = ground_truth[14:1486,14:1486]\n",
    "        #print(ground_truth.shape)\n",
    "        \n",
    "        prediction_binary[np.where(prediction==class_id)] = 1\n",
    "        label_binary[np.where(ground_truth==class_id)] = 1\n",
    "\n",
    "        prec, recall = calc_prec_recall(prediction_binary, label_binary, relax_factor)\n",
    "        f_measure = 2 * (prec * recall) / (prec + recall) \n",
    "        \n",
    "        jacard_index = jaccard_similarity_score(label_binary, prediction_binary, normalize=True)\n",
    "        \n",
    "        IoU = metrics.mean_IU(label_binary, prediction_binary)\n",
    "        freq_IoU = metrics.frequency_weighted_IU(prediction_binary, label_binary)\n",
    "        mean_acc = metrics.mean_accuracy(prediction_binary, label_binary)\n",
    "        pixel_acc = metrics.pixel_accuracy(prediction_binary, label_binary)\n",
    "\n",
    "        jaccard_average_similarity.append(jacard_index)\n",
    "        \n",
    "        mean_precision.append(prec)\n",
    "        mean_recall.append(recall)\n",
    "        mean_f1.append(f_measure)\n",
    "        \n",
    "        mean_IoU_list.append(IoU)\n",
    "        freq_IoU_list.append(freq_IoU)\n",
    "        mean_acc_list.append(mean_acc)\n",
    "        pixel_acc_list.append(pixel_acc)\n",
    "        \n",
    "        #print(precision_recall_fscore_support(label_binary, prediction_binary, average='weighted'))\n",
    "        \n",
    "        #print(image_name.strip(), \"-->\", prec, recall, f_measure, jacard_index, IoU)\n",
    "        \n",
    "    print(\"Mean prec:\", np.mean(mean_precision), \"Mean recall:\", np.mean(mean_recall), \"Mean f1:\", np.mean(mean_f1), \"Jaccard Index\", np.mean(jaccard_average_similarity))\n",
    "    print(\"Mean IoU:\", np.mean(mean_IoU_list), \"Mean freq IoU:\", np.mean(freq_IoU_list), \"Mean acc:\", np.mean(mean_acc_list), \"Mean pixel acc:\", np.mean(pixel_acc_list))\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1500)\n",
      "(1500, 1500)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAD8CAYAAABZ0jAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nikRFCBEUiYoQIigSFSFEUP4fx7TP5WVQGf4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4f49b9a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(prediction.shape)\n",
    "print(ground_truth.shape)\n",
    "\n",
    "class_id = 2\n",
    "prediction_binary = np.zeros((1500,1500), dtype=np.uint8)\n",
    "label_binary = np.zeros((1500,1500), dtype=np.uint8)\n",
    "\n",
    "\n",
    "prediction_binary[np.where(prediction==class_id)] = 1\n",
    "label_binary[np.where(ground_truth==class_id)] = 1\n",
    "\n",
    "plt.imshow(prediction_binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prec, recall = calc_prec_recall(prediction_binary, label_binary, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_measure = 2 * (prec * recall) / (prec + recall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7896968655091399 0.7240775016736896 0.7554649435920076\n"
     ]
    }
   ],
   "source": [
    "print(prec, recall, f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array([1,1,1,1,1])\n",
    "y_true = np.array([1,1,1,1,1])\n",
    "\n",
    "print(sum((y_pred == y_true).astype(int))/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_nv)",
   "language": "python",
   "name": "tf_nv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
